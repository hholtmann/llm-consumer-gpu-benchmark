{
  "name": "gemma3-27b-w4a16-rag-8k-c4",
  "model": "RedHatAI/gemma-3-27b-it-quantized.w4a16",
  "vllm": {
    "max_model_len": 9216,
    "gpu_memory_utilization": 0.9,
    "max_num_batched_tokens": 8192,
    "dtype": "auto",
    "tensor_parallel_size": 2
  },
  "aiperf": {
    "endpoint_type": "chat",
    "streaming": true,
    "concurrency": 4,
    "synthetic_input_tokens_mean": 8192,
    "output_tokens_mean": 512,
    "request_count": 500,
    "warmup_request_count": 5,
    "dataset_sampling_strategy": "shuffle"
  }
}